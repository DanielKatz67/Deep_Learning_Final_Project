{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-09T06:37:01.928042Z",
     "start_time": "2025-08-09T06:37:01.922171Z"
    }
   },
   "source": [
    "# Setup (PyTorch, paths, device, seeds)\n",
    "import os, random, math, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_fscore_support\n",
    "torch.manual_seed(42)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1084b15d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T06:40:46.582324Z",
     "start_time": "2025-08-09T06:37:03.274908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "# Use the returned path to set base_dir correctly\n",
    "base_dir = os.path.join(path, \"chest_xray\")\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir   = os.path.join(base_dir, 'val')\n",
    "test_dir  = os.path.join(base_dir, 'test')"
   ],
   "id": "bc7a8df29b6d692a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming download from 293601280 bytes (2169764155 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/paultimothymooney/chest-xray-pneumonia?dataset_version_number=2 (293601280/2463365435) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.29G/2.29G [03:27<00:00, 10.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T06:45:29.265074Z",
     "start_time": "2025-08-09T06:45:29.260774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train dir:\", train_dir)\n",
    "print(\"Val dir:\", val_dir)\n",
    "print(\"Test dir:\", test_dir)\n",
    "\n",
    "print(\"Train dir contents:\", os.listdir(train_dir))\n",
    "print(\"Val dir contents:\", os.listdir(val_dir))\n",
    "print(\"Test dir contents:\", os.listdir(test_dir))"
   ],
   "id": "ef61bd67727bf5c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dir: /Users/daniel/.cache/kagglehub/datasets/paultimothymooney/chest-xray-pneumonia/versions/2/chest_xray/train\n",
      "Val dir: /Users/daniel/.cache/kagglehub/datasets/paultimothymooney/chest-xray-pneumonia/versions/2/chest_xray/val\n",
      "Test dir: /Users/daniel/.cache/kagglehub/datasets/paultimothymooney/chest-xray-pneumonia/versions/2/chest_xray/test\n",
      "Train dir contents: ['.DS_Store', 'PNEUMONIA', 'NORMAL']\n",
      "Val dir contents: ['PNEUMONIA', 'NORMAL']\n",
      "Test dir contents: ['PNEUMONIA', 'NORMAL']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)"
   ],
   "id": "11dcf84058ebdd08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Datasets, DataLoaders, class weights (for imbalance)\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    # normalize to [-1,1] range (since we train from scratch)\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]),\n",
    "])\n",
    "\n",
    "eval_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]),\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(train_dir, transform=train_tfms)\n",
    "val_ds   = datasets.ImageFolder(val_dir,   transform=eval_tfms)\n",
    "test_ds  = datasets.ImageFolder(test_dir,  transform=eval_tfms)\n",
    "\n",
    "print(\"Classes:\", train_ds.classes, \"=>\", train_ds.class_to_idx)"
   ],
   "id": "4b402c8e3784eced"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "# Compute class weights for BCEWithLogitsLoss (pos_weight = N_neg / N_pos for label=1 class)\n",
    "# In ImageFolder, NORMAL -> 0, PNEUMONIA -> 1 (alphabetical)\n",
    "train_targets = torch.tensor([y for _, y in train_ds.samples])\n",
    "pos = (train_targets==1).sum().item()\n",
    "neg = (train_targets==0).sum().item()\n",
    "pos_weight = torch.tensor([neg / max(pos,1.0)], dtype=torch.float32)\n",
    "print(f\"Train counts -> NEG(NORMAL)={neg}, POS(PNEUMONIA)={pos}, pos_weight={pos_weight.item():.3f}\")"
   ],
   "id": "96f4b8e2328d2eb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 3 — CNN model as a class (__init__ + forward)\n",
    "class PneumoCNN(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "        # feature extractor\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),   # 112x112\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),   # 56x56\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),   # 28x28\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),   # 14x14\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),   # 7x7\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256*7*7, 512), nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)  # logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x  # logits if num_classes=1; shape [B,1]"
   ],
   "id": "4b6800f0ddcfe0c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = PneumoCNN(num_classes=1).to(device)\n",
    "model"
   ],
   "id": "3fd8cbc76d69b754"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Loss, Optimizer, LR scheduler\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))  # robust for class imbalance\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True) # monitors val accuracy"
   ],
   "id": "d38cc78f1fc3d7ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Utilities: train/eval loops\n",
    "def accuracy_from_logits(logits, targets):\n",
    "    # logits: [B,1], targets: [B]\n",
    "    probs = torch.sigmoid(logits).squeeze(1)\n",
    "    preds = (probs >= 0.5).long()\n",
    "    correct = (preds == targets.long()).sum().item()\n",
    "    return correct, preds, probs\n",
    "\n",
    "def run_one_epoch(model, loader, optimizer=None):\n",
    "    is_train = optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    n = 0\n",
    "    all_probs, all_targets = [], []\n",
    "\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            logits = model(images).squeeze(1)\n",
    "            loss = criterion(logits, targets.float())\n",
    "            if is_train:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        c, _, probs = accuracy_from_logits(logits.unsqueeze(1), targets)\n",
    "        epoch_loss += loss.item() * images.size(0)\n",
    "        correct += c\n",
    "        n += images.size(0)\n",
    "\n",
    "        all_probs.append(probs.detach().cpu())\n",
    "        all_targets.append(targets.detach().cpu())\n",
    "\n",
    "    avg_loss = epoch_loss / n\n",
    "    acc = correct / n\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    # Some environments may lack enough positive/negative samples for AUC early on; guard it\n",
    "    try:\n",
    "        auc = roc_auc_score(all_targets, all_probs)\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "\n",
    "    return avg_loss, acc, auc, all_probs, all_targets"
   ],
   "id": "ce630f22a6e4cb5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# CTraining over epochs with early stopping + checkpoint\n",
    "EPOCHS = 15\n",
    "patience = 4\n",
    "best_val_acc = -np.inf\n",
    "no_improve = 0\n",
    "ckpt_path = \"best_cnn_pneumonia.pt\"\n",
    "\n",
    "history = {\"train_loss\":[], \"train_acc\":[], \"train_auc\":[],\n",
    "           \"val_loss\":[], \"val_acc\":[], \"val_auc\":[]}\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_acc, tr_auc, _, _ = run_one_epoch(model, train_loader, optimizer)\n",
    "    va_loss, va_acc, va_auc, _, _ = run_one_epoch(model, val_loader, optimizer=None)\n",
    "\n",
    "    history[\"train_loss\"].append(tr_loss); history[\"train_acc\"].append(tr_acc); history[\"train_auc\"].append(tr_auc)\n",
    "    history[\"val_loss\"].append(va_loss);   history[\"val_acc\"].append(va_acc);   history[\"val_auc\"].append(va_auc)\n",
    "\n",
    "    scheduler.step(va_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} | \"\n",
    "          f\"Train: loss {tr_loss:.4f} acc {tr_acc:.4f} auc {tr_auc:.4f} | \"\n",
    "          f\"Val:   loss {va_loss:.4f} acc {va_acc:.4f} auc {va_auc:.4f}\")\n",
    "\n",
    "    # Early stopping & checkpoint\n",
    "    if va_acc > best_val_acc:\n",
    "        best_val_acc = va_acc\n",
    "        no_improve = 0\n",
    "        torch.save({\"model_state\": model.state_dict(),\n",
    "                    \"optimizer_state\": optimizer.state_dict(),\n",
    "                    \"epoch\": epoch}, ckpt_path)\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "print(f\"Training finished in {(time.time()-start)/60:.1f} min. Best val acc: {best_val_acc:.4f}\")"
   ],
   "id": "6940f5dd7c9308fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load best checkpoint (optional) and plot curves\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "\n",
    "def plot_curves(h):\n",
    "    fig, axs = plt.subplots(1,3, figsize=(16,4))\n",
    "    axs[0].plot(h[\"train_loss\"], label=\"train\"); axs[0].plot(h[\"val_loss\"], label=\"val\")\n",
    "    axs[0].set_title(\"Loss\"); axs[0].legend()\n",
    "    axs[1].plot(h[\"train_acc\"], label=\"train\"); axs[1].plot(h[\"val_acc\"], label=\"val\")\n",
    "    axs[1].set_title(\"Accuracy\"); axs[1].legend()\n",
    "    axs[2].plot(h[\"train_auc\"], label=\"train\"); axs[2].plot(h[\"val_auc\"], label=\"val\")\n",
    "    axs[2].set_title(\"ROC-AUC\"); axs[2].legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_curves(history)"
   ],
   "id": "b6edbe44d7058147"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Final test evaluation + confusion matrix, precision/recall/F1\n",
    "test_loss, test_acc, test_auc, probs, targets = run_one_epoch(model, test_loader, optimizer=None)\n",
    "preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "print(f\"TEST — loss: {test_loss:.4f} | acc: {test_acc:.4f} | auc: {test_auc:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(targets, preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\",\n",
    "      classification_report(targets, preds, target_names=test_ds.classes, digits=4))\n",
    "\n",
    "# Quick ROC curve\n",
    "fpr, tpr, _ = roc_curve(targets, probs)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr, lw=2)\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC Curve (Test)')\n",
    "plt.grid(True); plt.show()"
   ],
   "id": "2843d787f59a7656"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Inference helper (predict on a few samples)\n",
    "from PIL import Image\n",
    "\n",
    "def predict_image(path, model, tfms=eval_tfms):\n",
    "    model.eval()\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    x = tfms(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logit = model(x)\n",
    "        prob = torch.sigmoid(logit).item()\n",
    "    pred = int(prob >= 0.5)\n",
    "    return prob, pred  # probability of PNEUMONIA, predicted label (0 normal / 1 pneumonia)\n",
    "\n",
    "# Example:\n",
    "# p, yhat = predict_image(os.path.join(test_dir, \"PNEUMONIA\", os.listdir(os.path.join(test_dir,\"PNEUMONIA\"))[0]), model)\n",
    "# print(p, yhat)\n"
   ],
   "id": "91f49abba928a490"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
